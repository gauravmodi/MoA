{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'Predictive Analysis/Features Data v2/'\n",
    "\n",
    "dateparse2 = lambda dates: [pd.datetime.strptime(d, '%m/%d/%Y') for d in dates]\n",
    "\n",
    "df_all = read_csv(filepath_or_buffer=(path+'dense_df_all_predictors_LYLY.csv'), \n",
    "                   parse_dates=['Date'], date_parser=dateparse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'X', u'Date', u'Ridership', u'total_student_out_of_school_count',\n",
       "       u'LY.Ridership', u'LY2.Ridership', u'Plus_Holiday', u'Minus_Holiday',\n",
       "       u'Friday', u'Monday', u'Saturday', u'Sunday', u'Thursday', u'Tuesday',\n",
       "       u'Wednesday', u'Holiday_Decrease_Effect', u'January', u'February',\n",
       "       u'March', u'April', u'May', u'June', u'July', u'August', u'September',\n",
       "       u'October', u'November', u'December', u'Ridership_ma_7',\n",
       "       u'Ridership_ma_14', u'LY_3_1_3', u'LY_1_1_1',\n",
       "       u'LY_weekday_before_after', u'LY_7_before', u'LYLY_3_1_3',\n",
       "       u'LYLY_1_1_1', u'LYLY_weekday_before_after', u'LYLY_7_before'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.loc[:, ['Date', u'total_student_out_of_school_count', u'LY.Ridership', u'LY2.Ridership', \n",
    "               u'Plus_Holiday', u'Minus_Holiday', \n",
    "               u'Friday', u'Monday', u'Saturday', u'Sunday', \n",
    "               u'Thursday', u'Tuesday', u'Wednesday', 'Ridership']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all.loc[: ,[u'total_student_out_of_school_count', u'LY.Ridership', u'LY2.Ridership', \n",
    "               u'Plus_Holiday', u'Minus_Holiday', \n",
    "               u'Friday', u'Monday', u'Saturday', u'Sunday', \n",
    "               u'Thursday', u'Tuesday', u'Wednesday']]\n",
    "\n",
    "X= X.loc[~X['LY2.Ridership'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 30 The average silhouette_score is : 0.759498977172\n"
     ]
    }
   ],
   "source": [
    "clusterer = KMeans(n_clusters=4, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)\n",
    "silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "For n_clusters = 2 The average silhouette_score is : 0.9062715069\n",
      "For n_clusters = 3 The average silhouette_score is : 0.821256213618\n",
      "For n_clusters = 4 The average silhouette_score is : 0.759498977172\n",
      "For n_clusters = 5 The average silhouette_score is : 0.712707784323\n",
      "For n_clusters = 6 The average silhouette_score is : 0.69850544408\n",
      "For n_clusters = 7 The average silhouette_score is : 0.686736102832\n",
      "For n_clusters = 8 The average silhouette_score is : 0.581627997082\n",
      "For n_clusters = 9 The average silhouette_score is : 0.583276520171\n",
      "For n_clusters = 10 The average silhouette_score is : 0.543748437911\n",
      "For n_clusters = 11 The average silhouette_score is : 0.547639451346\n",
      "For n_clusters = 12 The average silhouette_score is : 0.543756502257\n",
      "For n_clusters = 13 The average silhouette_score is : 0.520481403213\n",
      "For n_clusters = 14 The average silhouette_score is : 0.522192784648\n",
      "For n_clusters = 15 The average silhouette_score is : 0.525573202837\n",
      "For n_clusters = 16 The average silhouette_score is : 0.519275724961\n",
      "For n_clusters = 17 The average silhouette_score is : 0.524655082167\n",
      "For n_clusters = 18 The average silhouette_score is : 0.501115516476\n",
      "For n_clusters = 19 The average silhouette_score is : 0.516993277967\n",
      "For n_clusters = 20 The average silhouette_score is : 0.49555365956\n",
      "For n_clusters = 21 The average silhouette_score is : 0.507945350933\n",
      "For n_clusters = 22 The average silhouette_score is : 0.476548945703\n",
      "For n_clusters = 23 The average silhouette_score is : 0.479238369379\n",
      "For n_clusters = 24 The average silhouette_score is : 0.504772401648\n",
      "For n_clusters = 25 The average silhouette_score is : 0.515579906052\n",
      "For n_clusters = 26 The average silhouette_score is : 0.491557654883\n",
      "For n_clusters = 27 The average silhouette_score is : 0.487007011449\n",
      "For n_clusters = 28 The average silhouette_score is : 0.469089377586\n",
      "For n_clusters = 29 The average silhouette_score is : 0.492408427727\n",
      "For n_clusters = 30 The average silhouette_score is : 0.493681286778\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "range_n_clusters = range(2, 31)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Estimated number of clusters: 11\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=1, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "# print(\"Adjusted Rand Index: %0.3f\"\n",
    "#       % metrics.adjusted_rand_score(labels_true, labels))\n",
    "# print(\"Adjusted Mutual Information: %0.3f\"\n",
    "#       % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "#       % metrics.silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 15)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Cluster'] = Series(labels)\n",
    "df_all.loc[df_all.Cluster == -1.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all.loc[df_all.Cluster == -1.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
